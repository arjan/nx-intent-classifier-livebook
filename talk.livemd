<!-- livebook:{"persist_outputs":true} -->

# Building an intent classifier using Nx, Axon and BERT

## Setup

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
Mix.install([
  {:req, "~> 0.2.0"},
  {:axon, "~> 0.1.0-dev", github: "elixir-nx/axon", branch: "main"},
  {:exla, "~> 0.1.0-dev", github: "elixir-nx/nx", sparse: "exla"},
  {:nx, "~> 0.1.0-dev", github: "elixir-nx/nx", sparse: "nx", override: true}
])
```

```output
* Getting axon (https://github.com/elixir-nx/axon.git - origin/main)
remote: Enumerating objects: 2646, done.        
remote: Counting objects: 100% (1822/1822), done.        
remote: Compressing objects: 100% (1077/1077), done.        
remote: Total 2646 (delta 1351), reused 1120 (delta 726), pack-reused 824        
* Getting exla (https://github.com/elixir-nx/nx.git)
remote: Enumerating objects: 10273, done.        
remote: Counting objects: 100% (1891/1891), done.        
remote: Compressing objects: 100% (197/197), done.        
remote: Total 10273 (delta 1775), reused 1713 (delta 1691), pack-reused 8382        
origin/HEAD set to main
* Getting nx (https://github.com/elixir-nx/nx.git)
remote: Enumerating objects: 10273, done.        
remote: Counting objects: 100% (1945/1945), done.        
remote: Compressing objects: 100% (194/194), done.        
remote: Total 10273 (delta 1831), reused 1770 (delta 1748), pack-reused 8328        
origin/HEAD set to main
Resolving Hex dependencies...
Dependency resolution completed:
New:
  castore 0.1.13
  elixir_make 0.6.3
  finch 0.8.3
  jason 1.2.2
  mime 2.0.2
  mint 1.4.0
  nimble_options 0.3.7
  nimble_pool 0.2.4
  req 0.2.0
  table_rex 3.1.1
  telemetry 1.0.0
  xla 0.2.0
* Getting req (Hex package)
* Getting xla (Hex package)
* Getting elixir_make (Hex package)
* Getting table_rex (Hex package)
* Getting finch (Hex package)
* Getting jason (Hex package)
* Getting mime (Hex package)
* Getting castore (Hex package)
* Getting mint (Hex package)
* Getting nimble_options (Hex package)
* Getting nimble_pool (Hex package)
* Getting telemetry (Hex package)
==> nimble_options
Compiling 3 files (.ex)
Generated nimble_options app
==> nimble_pool
Compiling 2 files (.ex)
Generated nimble_pool app
==> nx
Compiling 20 files (.ex)
Generated nx app
===> Analyzing applications...
===> Compiling telemetry
==> jason
Compiling 8 files (.ex)
Generated jason app
==> elixir_make
Compiling 1 file (.ex)
Generated elixir_make app
==> xla
Compiling 2 files (.ex)
Generated xla app

13:30:43.740 [info]  Found a matching archive (xla_extension-x86_64-linux-cpu.tar.gz), going to download it

13:30:52.184 [info]  Successfully downloaded the XLA archive
==> exla
Unpacking /home/arjan/.cache/xla/0.2.0/cache/download/xla_extension-x86_64-linux-cpu.tar.gz into /home/arjan/.cache/mix/installs/elixir-1.12.2-erts-12.1.3/a04fb5c0bd902d7099cad6291c1b8daa/deps/exla/exla/cache
mkdir -p /home/arjan/.cache/mix/installs/elixir-1.12.2-erts-12.1.3/a04fb5c0bd902d7099cad6291c1b8daa/_build/dev/lib/exla/priv
ln -sf /home/arjan/.cache/mix/installs/elixir-1.12.2-erts-12.1.3/a04fb5c0bd902d7099cad6291c1b8daa/deps/exla/exla/cache/xla_extension/lib /home/arjan/.cache/mix/installs/elixir-1.12.2-erts-12.1.3/a04fb5c0bd902d7099cad6291c1b8daa/_build/dev/lib/exla/priv/lib
g++ -fPIC -I/home/arjan/.asdf/installs/erlang/24.1.3/erts-12.1.3/include -isystem cache/xla_extension/include -O3 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-comment -shared -std=c++14 c_src/exla/exla.cc c_src/exla/exla_nif_util.cc c_src/exla/exla_client.cc -o /home/arjan/.cache/mix/installs/elixir-1.12.2-erts-12.1.3/a04fb5c0bd902d7099cad6291c1b8daa/_build/dev/lib/exla/priv/libexla.so -L/home/arjan/.cache/mix/installs/elixir-1.12.2-erts-12.1.3/a04fb5c0bd902d7099cad6291c1b8daa/_build/dev/lib/exla/priv/lib -lxla_extension -Wl,-rpath,'$ORIGIN/lib'
c_src/exla/exla_client.cc: In function ‘tensorflow::StatusOr<std::vector<exla::ExlaBuffer*> > exla::UnpackRunArguments(ErlNifEnv*, ERL_NIF_TERM, exla::ExlaClient*, int)’:
c_src/exla/exla_client.cc:89:19: warning: redundant move in return statement [-Wredundant-move]
   89 |   return std::move(arg_buffers);
      |          ~~~~~~~~~^~~~~~~~~~~~~
c_src/exla/exla_client.cc:89:19: note: remove ‘std::move’ call
Compiling 15 files (.ex)
Generated exla app
==> castore
Compiling 1 file (.ex)
Generated castore app
==> mint
Compiling 1 file (.erl)
Compiling 23 files (.ex)
Generated mint app
==> finch
Compiling 11 files (.ex)
Generated finch app
==> mime
Compiling 1 file (.ex)
Generated mime app
==> req
Compiling 4 files (.ex)
Generated req app
==> table_rex
Compiling 7 files (.ex)
Generated table_rex app
==> axon
Compiling 20 files (.ex)
Generated axon app
```

```output
:ok
```

## The embeddings server

The embeddings server is a python program that runs on the following URL:

```elixir
server = "http://localhost:5000/encode"
```

```output
"http://localhost:5000/encode"
```

The Python repo for it is [located on Github](https://github.com/arjan/embeddings-server-ref). 
Lets try out the embedding server:

```elixir
bytes = Req.get!("#{server}?q=Hello+world").body
```

```output
<<158, 9, 215, 60, 46, 121, 91, 60, 227, 138, 148, 187, 244, 131, 178, 188, 212, 113, 95, 61, 165,
  189, 162, 187, 119, 23, 218, 59, 209, 227, 250, 60, 183, 214, 188, 187, 228, 124, 149, 187, 202,
  36, 89, 187, 16, 164, 70, 189, 53, 48, ...>>
```

Lets put this data into a Tensor

```elixir
bytes |> Nx.from_binary({:f, 32})
```

```output
#Nx.Tensor<
  f32[768]
  [0.026249703019857407, 0.013395590707659721, -0.004533158149570227, -0.02179143577814102, 0.05455191433429718, -0.004966455046087503, 0.006655629258602858, 0.0306262094527483, -0.0057629006914794445, -0.004562007263302803, -0.003313350025564432, -0.0484963059425354, -0.01136403251439333, 0.035077471286058426, 0.09309472143650055, -0.08668740838766098, 0.05108659714460373, 0.009886144660413265, -0.06356935948133469, -0.008550175465643406, 0.007054428104311228, -0.0038623828440904617, 0.024744290858507156, 0.04288496449589729, 0.03509416803717613, -0.029848242178559303, 0.010252568870782852, 0.022344909608364105, 0.020889967679977417, 0.009492211975157261, -0.03304436802864075, -0.012284141965210438, 0.05352891981601715, 0.025429198518395424, 2.0221782506268937e-6, -0.03419104218482971, 0.009610011242330074, -0.0164845772087574, 0.005609493236988783, -0.0042500682175159454, -0.022801246494054794, 0.04035472869873047, 0.0030519948340952396, 0.03137265890836716, -0.010812385939061642, -0.035570915788412094, 0.02229289896786213, 0.0016871250700205564, 0.00207726564258337, 0.02311626449227333, ...]
>
```

```elixir
dim = bytes |> Nx.from_binary({:f, 32}) |> Nx.size()
```

```output
768
```

Okay, so that works, we can make a tensor out of a sentence. In the next part we are going to extend this to translate a list of annotated sentences into an array of vectors with their corresponding labels.

## Loading the training data

Now, we are going to translate a list of annotated sentences into an array of vectors with their corresponding labels.
This is the input file:

```elixir
json_data = "disco.json" |> File.read!() |> Jason.decode!()
```

```output
[
  %{
    "id" => "faq_about",
    "training_data" => ["tell me something about yourself", "what are you",
     "i want to know everything about you", "i want to know about you", "why are you here",
     "I want to know you better", "describe yourself", "talk about yourself",
     "explain what you are", "what is this exactly", "are you a chatbot",
     "i want to know more about you", "can you introduce yourself", "please introduce yourself",
     "tell me about yourself"]
  },
  %{
    "id" => "faq_purpose",
    "training_data" => ["what is the purpose", "i want to know what your purpose is",
     "what is the idea?", "what do you need from me?", "what is the reason for your existence?",
     "what do you want from me?", "can you tell me what your purpose is?",
     "what is the purpose exactly?", "what is your purpose?", "what is the idea with this"]
  },
  %{
    "id" => "faq_about_us",
    "training_data" => ["more details on this project", "i have a question about the company",
     "about the project", "tell me about your company", "can you tell some more about you guys",
     "what do you guys do", "give me more information about your game",
     "i'm looking for more information about your company", "who made this project",
     "who made this game", "who are the builders of this project",
     "who are the creators of this game"]
  },
  %{
    "id" => "faq_address",
    "training_data" => ["where are you based?", "what is the location of your company?",
     "can you tell me the address of your company?", "can you tell me the address?",
     "what's your address exactly?", "where are you?", "in which country are you guys based?",
     "where are you guys located?", "on what address is your office?",
     "on what street is your office?", "what is your office address?", "where is your office?",
     "where are you located?", "what is your address?"]
  },
  %{
    "id" => "faq_contactdetails",
    "training_data" => ["can you share with me your contact details", "i want contact details",
     "i want your contact information", "how can i get in touch with you guys",
     "how can i get in touch with your company", "how can i reach you",
     "do you have information about how to reach you", "what are your contact details",
     "I'm looking for your contact details", "give me your contactdetails",
     "give me your contact details"]
  },
  %{
    "id" => "faq_email",
    "training_data" => ["i would like to mail",
     "I would like to mail to the sales department, do you have an email",
     "how can i reach you by email?", "what is your email address?", "tell me your email",
     "do you have an email address?", "please give me your email", "your email please",
     "where can i send my emails to?", "how can i find email address?",
     "to which address can i send an email?", "what is your email?"]
  },
  %{
    "id" => "faq_phone",
    "training_data" => ["can i call the service desk?", "phone number", "phonenumber",
     "what is the phone number of the customer service department?", "can i give you a call",
     "i want to call the helpdesk", "what is phone number of customer services",
     "what is your phone number?", "i want to give you a call", "can i call you up?",
     "how can i call you?"]
  },
  %{
    "id" => "faq_what_do_i_need",
    "training_data" => ["What do I need to join a distance disco?", "What do I need to join?",
     "How can I join?", "What do I need"]
  },
  %{
    "id" => "faq_how_does_it_work",
    "training_data" => ["What am I supposed to do?", "How does this work?",
     "How does the disco work?", "how does it work"]
  },
  %{
    "id" => "faq_webcam_does_not_work",
    "training_data" => ["My webcam does not work?", "My laptop camera is not working",
     "My webcam image stays black", "i have no camera", "my camera stays black",
     "browser does not ask for camera permission"]
  },
  %{
    "id" => "faq_black_screen",
    "training_data" => ["I only see black screens?", "I do not see any video frames"]
  },
  %{
    "id" => "faq_mobile",
    "training_data" => ["will it work on ipad", "can I use my tablet?", "can I use my android?",
     "does it work on an android tablet?", "Can I use my phone or tablet?",
     "does it work on an iphone?", "i want to view it on an ipad", "i want it on an iphone"]
  },
  %{
    "id" => "faq_freeze",
    "training_data" => ["The music stopped / everything seems to freeze?", "My computer froze",
     "I do not see any video anymore", "Everybody is frozen"]
  },
  %{
    "id" => "faq_mic_is_off",
    "training_data" => ["How do I switch on my mic?", "I want to talk during the disco",
     "can you talk during the disco", "the sound is off", "I cannot hear people",
     "can I talk to other people while dancing?"]
  },
  %{
    "id" => "faq_headphones",
    "training_data" => ["Do I need headphones?", "should I use headphones"]
  },
  %{
    "id" => "faq_chat",
    "training_data" => ["Can I chat during the disco?", "I want to chat while we are dancing "]
  },
  %{
    "id" => "faq_grid_view",
    "training_data" => ["I only see one person very big?", "I see one person very large",
     "there is one person zoomed in"]
  },
  %{
    "id" => "faq_zoom_in",
    "training_data" => ["How can I zoom in on one person?", "Can I view just one person?",
     "I want to view only a single person"]
  },
  %{
    "id" => "faq_skip_song",
    "training_data" => ["I hate this song", "What if I don't like a song",
     "I want to go to the next song", "next song please", "skip this song"]
  },
  %{
    "id" => "faq_pause",
    "training_data" => ["I want to take a break to get some fresh drinks.",
     "I want to take a break", "I need to rest for a while"]
  },
  %{
    "id" => "faq_own_music",
    "training_data" => ["i want to listen to my own music",
     "Can I use my own music with Distance Disco?", "i want my own playlist",
     "can I play a customized playlist?", "can I connect spotify account?"]
  },
  %{
    "id" => "faq_winning",
    "training_data" => ["is there a prize to win?", "what can I win?", "how can I win this game?",
     "i want a prize", "I think I have won"]
  },
  %{
    "id" => "faq_howmany",
    "training_data" => ["How many people can join?", "With how many persons can I participate?",
     "How many folks can join together in the disco?", "How many persons?",
     "Is there a maximum capacity for a disco?", "What is the best size for a disco?",
     "How big can a disco become?", "How many people can play the game?"]
  },
  %{
    "id" => "faq_donate",
    "training_data" => ["Can I still donate to your project?", "I want to give you some money",
     "I want to donate", "I want to donate some money"]
  },
  %{
    "id" => "faq_price",
    "training_data" => ["How much does it cost?", "How much do I have to pay?", "Do I need money??",
     "How much money does it cost?", "What is the price for a distance disco?",
     "What is the price?", "Is the price to make a disco per person or total?",
     "Do participants need to pay?", "How much does everyone needs to pay?"]
  },
  %{
    "id" => "faq_try_out",
    "training_data" => ["Can I first try out the disco before buying?", "Is there a trial version?",
     "Can I test?", "can I test a disco before I buy it", "is there a way to try it out first"]
  },
  %{
    "id" => "faq_change_time",
    "training_data" => ["Is it possible to change the time of the disco?",
     "I want to change the start time of the disco", "I want to postpone the disco",
     "can I make the disco start sooner", "i want the disco to start earlier",
     "can I make the disco start later? "]
  },
  %{
    "id" => "faq_email_span",
    "training_data" => ["i didn't receive an email after creating a disco",
     "I don't get email messages", "E-mail does not arrive", "I did not get the confirmation mail"]
  },
  %{
    "id" => "faq_playlist_option",
    "training_data" => ["Do you have music for kids?", "Do you have music for children?",
     "Do you have a playlist for kids?", "Do you have a playlist for children?",
     "Is there a special version for children", "Do you have a carnaval playlist?",
     "What kind of music do you have?", "What kind of songs can I expect?", "Can I create a theme?",
     ""]
  },
  %{
    "id" => "faq_when_does_it_start",
    "training_data" => ["When does the disco start?", "Can I join the disco before it starts?",
     "Is there a waiting room for people that come too early?", "When does the disco open?"]
  },
  %{
    "id" => "fallback",
    "training_data" => ["forklar hvad du er", "explain what you are", "Rede über dich selbst",
     "erkläre was du bist", "habla de ti mismo", "Kuvaile itseäsi", "décrivez-vous",
     "Ik wil alles van je weten", "Jeg vil gerne eskalere til et menneske",
     "jeg sætter pris på det", "Danke, Mann", "ja, ich bin sicher", "das ist der, den ich meine",
     "can we do that one more time please?", "can i try again please", "nothing", "no don't stop",
     ...]
  }
]
```

Lets transform it into a list of labels and a list of sentences:

```elixir
{labels, utterances} =
  json_data
  |> Enum.flat_map(fn %{"id" => id, "training_data" => training_data} ->
    training_data |> Enum.map(&{id, &1})
  end)
  |> Enum.unzip()
```

```output
{["faq_about", "faq_about", "faq_about", "faq_about", "faq_about", "faq_about", "faq_about",
  "faq_about", "faq_about", "faq_about", "faq_about", "faq_about", "faq_about", "faq_about",
  "faq_about", "faq_purpose", "faq_purpose", "faq_purpose", "faq_purpose", "faq_purpose",
  "faq_purpose", "faq_purpose", "faq_purpose", "faq_purpose", "faq_purpose", "faq_about_us",
  "faq_about_us", "faq_about_us", "faq_about_us", "faq_about_us", "faq_about_us", "faq_about_us",
  "faq_about_us", "faq_about_us", "faq_about_us", "faq_about_us", "faq_about_us", "faq_address",
  "faq_address", "faq_address", "faq_address", "faq_address", "faq_address", "faq_address",
  "faq_address", "faq_address", "faq_address", "faq_address", "faq_address", ...],
 ["tell me something about yourself", "what are you", "i want to know everything about you",
  "i want to know about you", "why are you here", "I want to know you better", "describe yourself",
  "talk about yourself", "explain what you are", "what is this exactly", "are you a chatbot",
  "i want to know more about you", "can you introduce yourself", "please introduce yourself",
  "tell me about yourself", "what is the purpose", "i want to know what your purpose is",
  "what is the idea?", "what do you need from me?", "what is the reason for your existence?",
  "what do you want from me?", "can you tell me what your purpose is?",
  "what is the purpose exactly?", "what is your purpose?", "what is the idea with this",
  "more details on this project", "i have a question about the company", "about the project",
  "tell me about your company", "can you tell some more about you guys", "what do you guys do",
  "give me more information about your game", "i'm looking for more information about your company",
  "who made this project", "who made this game", "who are the builders of this project",
  "who are the creators of this game", "where are you based?",
  "what is the location of your company?", "can you tell me the address of your company?",
  "can you tell me the address?", "what's your address exactly?", "where are you?",
  "in which country are you guys based?", "where are you guys located?",
  "on what address is your office?", "on what street is your office?",
  "what is your office address?", ...]}
```

Let's also save the number of samples:

```elixir
n_samples = Enum.count(utterances)
```

```output
227
```

And the number of labels:

```elixir
n_labels = labels |> Enum.uniq() |> Enum.count()
```

```output
31
```

## Encoding the training data

First of all, the labels. We want to encode these as numbers instead of text labels, 
and make them into a [1-hot encoded](https://en.wikipedia.org/wiki/One-hot) tensor:

```elixir
lookup = labels |> Enum.uniq() |> Enum.with_index() |> Map.new()
reverse_lookup = lookup |> Enum.map(fn {k, v} -> {v, k} end) |> Map.new()

train_labels =
  labels
  |> Enum.map(&lookup[&1])
  |> Nx.tensor()
  |> Nx.new_axis(-1)
  |> Nx.equal(Nx.tensor(Enum.to_list(0..(n_labels - 1))))
```

```output
#Nx.Tensor<
  u8[227][31]
  [
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...],
    ...
  ]
>
```

Now, lets convert the utterances to a tensor. We do this the same way as before, but now with a POST method to the embeddings server because we are encoding many sentences in one request:

```elixir
body = utterances |> Enum.map(&{:q, &1}) |> URI.encode_query()

headers = %{"content-type" => "application/x-www-form-urlencoded"}
data = Req.post!(server, body, headers: headers).body
```

```output
<<244, 141, 20, 58, 120, 17, 172, 60, 118, 112, 107, 60, 160, 41, 106, 188, 187, 186, 2, 60, 43,
  248, 3, 60, 27, 143, 218, 188, 169, 179, 124, 189, 54, 107, 237, 188, 100, 101, 170, 188, 105,
  212, 113, 61, 199, 137, 248, 60, 95, 4, ...>>
```

... and make it into a tensor again, shaped accordingly:

```elixir
train_data = Nx.from_binary(data, {:f, 32}) |> Nx.reshape({n_samples, dim})
```

```output
#Nx.Tensor<
  f32[227][768]
  [
    [5.666904617100954e-4, 0.02100442349910736, 0.01437007449567318, -0.014292150735855103, 0.007979090325534344, 0.008054773323237896, -0.026679566130042076, -0.06169477477669716, -0.028981786221265793, -0.02080029994249344, 0.059040460735559464, 0.030339134857058525, 0.04639088734984398, 0.02764446847140789, 0.0678764060139656, -0.011913690716028214, 0.01239096187055111, -0.09189336746931076, 0.040982410311698914, -0.01296217367053032, -0.041586246341466904, 0.04403846710920334, -0.019316760823130608, 0.007623355370014906, -0.008245360106229782, 0.02004585973918438, 0.02365204319357872, 0.009900560602545738, 0.02454863116145134, 0.046415530145168304, 0.008115795440971851, -0.030796034261584282, 0.018966753035783768, -0.05050976201891899, 1.6579461998844636e-6, 0.010591953992843628, 0.02351311594247818, 3.382427166798152e-5, -0.0018564224010333419, -0.03629390150308609, -0.006299884989857674, 0.01904321275651455, 0.03704962879419327, 0.037280965596437454, 0.0197854433208704, -0.043206095695495605, 0.006026810966432095, 0.05071476846933365, -0.037018053233623505, 0.02615806832909584, ...],
    ...
  ]
>
```

## Training the classifier

Alright! now the fun stuff can start. let's use *Axon* to train a classifier. I use a pretty
standard neural net here with *softmax* activation. You know what they say about AI:

![XKCD AI](https://imgs.xkcd.com/comics/machine_learning.png)

But for reference, I adapted the model below from the 
[Axon MNIST example](https://github.com/elixir-nx/axon/blob/main/examples/mnist.exs):

```elixir
model =
  Axon.input({nil, dim})
  |> Axon.dense(128, activation: :relu)
  |> Axon.dense(n_labels, activation: :softmax)
```

```output
--------------------------------------------------
                      Model
==================================================
 Layer                    Shape        Parameters
==================================================
 input_52 ( input )       {nil, 768}   0
 dense_55 ( dense )       {nil, 128}   98432
 relu_56 ( relu )         {nil, 128}   0
 dense_59 ( dense )       {nil, 31}    3999
 softmax_60 ( softmax )   {nil, 31}    0
--------------------------------------------------

```

And let's train it

```elixir
epochs = 10
bs = 30

data =
  Stream.zip(
    Nx.to_batched_list(train_data, bs),
    Nx.to_batched_list(train_labels, bs)
  )

model_state =
  model
  |> Axon.Loop.trainer(:categorical_cross_entropy, Axon.Optimizers.adamw(0.005))
  |> Axon.Loop.metric(:accuracy, "Accuracy")
  |> Axon.Loop.run(data, epochs: epochs, compiler: EXLA)
```

```output
%{
  "dense_55" => %{
    "bias" => #Nx.Tensor<
      f32[128]
      [0.06802036613225937, 0.04141165688633919, 0.07990986853837967, 0.10343334823846817, 0.07487976551055908, 0.04030073806643486, 0.07435285300016403, 0.07410381734371185, 0.10781633853912354, 0.07034897804260254, 0.07889334857463837, 0.06954821199178696, 0.0784880518913269, 0.08748504519462585, 0.11159183084964752, 0.08253017067909241, 0.0897999107837677, 0.12754641473293304, 0.05993274599313736, 0.07714249193668365, 0.044043779373168945, 0.10082678496837616, 0.08139707148075104, 0.12725363671779633, 0.1251058727502823, 0.05917137488722801, 0.11485002934932709, 0.0898573026061058, 0.08941067010164261, 0.07164230942726135, 0.0844305232167244, 0.08608049899339676, 0.05346555635333061, 0.09327681362628937, 0.04076335206627846, 0.05760250985622406, 0.054446298629045486, 0.08501111716032028, 0.045558370649814606, 0.12435875087976456, 0.10160014778375626, 0.09837456047534943, 0.027519041672348976, 0.11294278502464294, 0.05245416611433029, 0.062083352357149124, 0.09171668440103531, 0.08139600604772568, ...]
>,
    "kernel" => #Nx.Tensor<
      f32[768][128]
      [
        [0.05522332340478897, 0.10557464510202408, -0.07270319759845734, -0.11672037094831467, -0.03256002068519592, 0.18484307825565338, 0.1495603322982788, -0.08556834608316422, 0.1272166222333908, -0.0648411214351654, 0.04019242897629738, 0.15709422528743744, 0.1030583456158638, 0.05182214826345444, -0.16951242089271545, -0.0633164569735527, 0.13086622953414917, -0.009594166651368141, -0.07876621186733246, -0.02528369054198265, -0.05994374305009842, -0.048659756779670715, 0.04628845676779747, -0.1156541109085083, 0.0029700601007789373, 0.13893936574459076, 0.06975705176591873, 0.12139754742383957, 0.04169697314500809, -0.04728555679321289, 0.02310364507138729, -0.02448054403066635, 0.11769043654203415, -0.05477152764797211, 0.09268129616975784, 0.12570048868656158, 0.13049884140491486, -0.03751211240887642, 0.03964780643582344, -0.22572290897369385, 0.0743158608675003, 0.08456572890281677, 0.01110747642815113, 0.0294719859957695, 0.16440285742282867, -0.018156418576836586, -0.08214323967695236, ...],
        ...
      ]
>
  },
  "dense_59" => %{
    "bias" => #Nx.Tensor<
      f32[31]
      [0.004464761354029179, -0.015419981442391872, -0.05114804580807686, 0.011162453331053257, -0.021569693461060524, 0.004940531682223082, -0.00843688566237688, -0.04356199875473976, -0.060028448700904846, -0.027506226673722267, -0.07251541316509247, -0.002601702930405736, -0.020433351397514343, -0.012113031931221485, -0.07460899651050568, -0.07447356730699539, -0.04981473088264465, -0.06008082255721092, -0.011951685883104801, -0.038509346544742584, -0.014429395087063313, -0.0171605683863163, -0.023430442437529564, -0.05171312391757965, -0.005843278486281633, -0.029818840324878693, -0.014169183559715748, -0.0256306454539299, 0.007986839860677719, -0.013697072863578796, 0.02285125106573105]
>,
    "kernel" => #Nx.Tensor<
      f32[128][31]
      [
        [-0.24965648353099823, -0.09539727866649628, -0.16944310069084167, -0.4033063054084778, 0.05994131416082382, -0.24846555292606354, 0.14573760330677032, 0.1469627171754837, 0.010239873081445694, 0.134626105427742, -0.09099747240543365, 0.15354135632514954, -0.4293554127216339, 0.11945711076259613, 0.09059445559978485, -0.1008581891655922, -0.08754189312458038, -0.22661490738391876, 0.04963098093867302, -0.11491436511278152, 0.2026008814573288, -0.41230159997940063, 0.09329710155725479, -0.09979108721017838, 0.23289455473423004, 0.16207630932331085, -0.11300478875637054, 0.08119631558656693, 0.07214358448982239, -0.24371270835399628, -0.1489981859922409],
        [0.040426284074783325, 0.1603539139032364, -0.01223025657236576, 0.20564274489879608, 0.1763460636138916, -0.1019832044839859, 0.08962119370698929, -0.14682042598724365, -0.18257923424243927, -0.0473196879029274, -0.12985289096832275, -0.3472805321216583, -0.3571431636810303, -0.1952640414237976, -0.28986987471580505, ...],
        ...
      ]
>
  }
}
```

Done! Now let's see if the classifier works...

## Evaluation

Let's create an input control where we can get an utterance from the user, and then encode 
it into a tensor:

<!-- livebook:{"livebook_object":"cell_input","name":"test sentence","type":"text","value":"what are you"} -->

```elixir
utterance = IO.gets("test sentence: ") |> String.trim()

test_tensor =
  Req.get!(server <> "?q=" <> URI.encode(utterance)).body
  |> Nx.from_binary({:f, 32})
  |> Nx.reshape({1, dim})
```

```output
#Nx.Tensor<
  f32[1][768]
  [
    [0.029761625453829765, 0.008596966043114662, 0.008777379989624023, -0.0445234477519989, -0.00790360290557146, 0.005799494218081236, -0.01698037050664425, 0.0018285870319232345, -0.0035022879019379616, 0.01592097245156765, 0.04143083468079567, -0.048225462436676025, 0.0234849750995636, 0.029680827632546425, 0.0390826053917408, -0.01177502516657114, 0.029436256736516953, 0.008167317137122154, -0.05014226585626602, -0.010738668031990528, -0.054664209485054016, 0.005391014739871025, 0.06420029699802399, -0.02763916552066803, -0.016854390501976013, -0.020366691052913666, -0.014999444596469402, -0.014744148589670658, -0.05502669885754585, 0.01226879097521305, 0.04178260639309883, -0.060308415442705154, 0.034837350249290466, 0.011259087361395359, 2.2928372800379293e-6, 0.044590167701244354, 0.01575983315706253, -0.01966875232756138, -0.008625345304608345, 0.0017860850784927607, 0.03679473698139191, -0.01607293263077736, 0.036904145032167435, 0.03108036145567894, -0.020923128351569176, -0.029780451208353043, 0.06779435276985168, 0.0263068787753582, 0.012113289907574654, 0.02006911300122738, ...]
  ]
>
```

And here we call the *predict* function to retrieve the one-hot encoding prediction 
for the feature vector:

```elixir
require Axon
[index] = Axon.predict(model, model_state, test_tensor) |> Nx.argmax() |> Nx.to_flat_list()
reverse_lookup[index]
```

```output
"faq_about"
```
